\section{Methodology}
\label{sec:methodology}
Browser fingerprinting is possible by investigating different kinds of features that the target user's browser has. Also, some of the attacks target a specific type of browser feature. So To be able to answer questions about browser fingerprintability and browser vulnerabilities, we need to have access to a huge amount of browser feature and vulnerability data. In the next subsections, we explain the process we applied to collect browser features and vulnerability data.


\subsection{Feature Gathering}

We collect feature sets from browsers (i.e., browserprints) when they load an instrumented web page.
We use the term \textit{feature} to describe JavaScript objects, methods, and property values built into the global namespace of the browser's JavaScript implementation (i.e., the \texttt{window} object).
This definition is obviously JavaScript-centric, but is unambiguous and naturally scalable, as we can automate collection of features from many different browsers using standard scripting and crawling techniques.

\subsubsection{Collection System}

The heart of our collection system is a custom web application that automatically captures and archives a visiting browser's full feature set on page load.
These feature sets are constructed by using JavaScript to traverse the tree of non-cyclic JavaScript object references accessible from a pristine (i.e., unmodified) \texttt{window} object and collecting the full feature names encountered during the traversal.
Each feature name comprises the sequence of property names leading from the global object to a given built-in JavaScript value.
The traversal code is careful to not modify this object (which doubles as the global variable namespace) in any way, to avoid contaminating the resulting set of feature names.
Captured feature sets are stored in a database, tagged with identifying metadata such as the browser's User-Agent string.

\subsubsection{Browser Testing}

We decided to target Google Chrome and Mozilla Firefox browsers in our paper. We are only testing major browser versions that are released during March 2016 up to April 2020. For chrome, this will be Chrome version 49 to Chrome 81. For Firefox, this will be Firefox 45 to Firefox 75. We ran the feature extractor script for each of these browser versions and extracted feature data for all of these browsers.

\ali{Do we need to tell why we chose this period? The reason was that the script did not work for older browsers.}

The platform that we used to run the tests on each browser was the BrowserStack website. BrowserStack is a cloud web and mobile testing platform that enables developers to test their websites and mobile applications across on-demand browsers, operating systems, and real mobile devices.
We have also developed an automated browser testing platform that can be used for the browser versions that are not included in Browserstack's website. But in this paper, we keep it simple and only test major browser versions for Chrome and Firefox. All of these versions exist in Browserstack's platform.


\subsection{Vulnerability Gathering}
One major source of information for security vulnerabilities is the CVE (Common Vulnerabilities and Exposures) dataset,
which is hosted by MITRE. CVE is a dictionary of publicly disclosed cybersecurity vulnerabilities and exposures. Each CVE entry
has a unique CVE identifier, a general description, and several references to one or more external information sources of
the vulnerability.

For our study, we used the CVE data from the National Vulnerability Database
(NVD) which is provided by the National Institute of Standards and Technology (NIST).
For each CVE entry in this dataset, we extracted the description, the affected product and version information, and the severity. After that, we parsed this data and generated a CVE entry list for each browser version in our dataset. This new dataset was the base of our vulnerability and feature analysis in our paper.

